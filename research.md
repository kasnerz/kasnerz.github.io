---
layout: article
title: Research
permalink: /research/
---

I work on building **language generation systems** for bringing insights from **structured data**. 

Here is an illustration of how such data-to-text generation may look like:
<img src="/assets/d2t.png" alt="d2t" style="max-width: 90%; margin: auto;">

I focus on improving accuracy of neural-based systems & extending their applicability to multiple domains with various end-goals, data formats, and language styles.

To achive that, I combine two approaches (see [[1]](#neural_pipeline), [[2]](#iterative_editing), [[3]](#text_in_context)):
- using **templates and rules** for transforming the data to text,
- using **pretrained neural language models** such as BART or T5 for postprocessing the text.

My other research interests (ranging from "I digged into that a little" up to "if only I had more time") include:
- evaluating quality of generated texts,
- story generation,
- logical and commonsense reasoning,
- language processing in human brain.



## Selected publications
<!-- See my **<img src="/assets/icons/scholar.png" style="display: inline"> [Google Scholar](https://scholar.google.cz/citations?user=6NnuRB8AAAAJ)** profile for the full list of my publications. -->