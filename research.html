---
layout: default
title: Research
---

<h2>Publications</h2>

<h3>2021</h3>
<div class="paper">

    <div class="row">
        <div class="col-md-8 paper-title">
        <b>Text-in-Context: Token-Level Error Detection for Table-to-Text Generation
        </b> 
        </div>
        <div class="col-md-4 paper-buttons">
            <a href="https://aclanthology.org/2021.inlg-1.25/" class="btn btn-acl" role="button"><i class="fa fa-file-pdf"></i></a>
            <a href="/assets/papers/pdf/2021_text_in_context_poster.pdf" target="_blank" class="btn btn-poster" role="button"><i class="fa fa-file-invoice"></i></a>
            <a href="https://github.com/kasnerz/accuracySharedTask_CUNI-UPF" target="_blank" class="btn btn-code" role="button"><i class="fa fa-github"></i></a>
        </div>
    </div>
        <div class="paper-authors">
        <i>Zdeněk Kasner, Simon Mille, Ondřej Dušek; INLG 2021</i>
        </div>
        <div class="paper-desc" style="margin-top: 10px">
           How to automatically detect which parts of the generated text do not correspond to the data? In our submission for the <a href="https://github.com/ehudreiter/accuracySharedTask">Shared Task in Evaluating Accuracy 2021</a>, we devise a 3-step approach combining a rule-based system with pretrained language models. And our approach was the best out of four submitted metrics!</a>
        </div>
        <div class="paper-img">
            <img src="/assets/papers/2021_text_in_context.png">
        </div>
    </div>


<h3>2020</h3>


<div class="paper">

<div class="row">
    <div class="col-md-9 paper-title">
    <b>Train Hard, Finetune Easy: Multilingual Denoising for RDF-to-Text Generation 
    </b> 
    </div>
    <div class="col-md-3  paper-buttons">
        <a href="https://www.aclweb.org/anthology/2020.webnlg-1.20/" class="btn btn-acl" role="button"><i class="fa fa-file-pdf"></i></a>
    </div>
</div>
    <div class="paper-authors">
    <i>Zdeněk Kasner, Ondřej Dušek; INLG 2020</i>
    </div>
    <div class="paper-desc" style="margin-top: 10px">
       <i>Data</i> == <i>noisy text</i>. That's definitely an overgeneralization, oversimplification... but um, it works! We succesfully generate text from DBPedia data in <i>English</i> and <i>Russian</i> just by finetuning mBART - a pretrained multilingual denoising autoencoder. This is our submission for the <a href="https://webnlg-challenge.loria.fr/challenge_2020/">WebNLG Challenge 2020</a>, presented at the <a href="https://webnlg-challenge.loria.fr/workshop_2020/">3rd Workshop on Natural Language Generation from the Semantic Web.</a>
    </div>
    <div class="paper-img">
        <img src="/assets/papers/2020_mbart.png">
    </div>
</div>

<hr>
<div class="paper">
    <div class="paper-extra">
        <i class="fa fa-award"></i><b> INLG 2020 Best Short Paper Award</b>
    </div>
    <div class="row">
    
    <div class="col-md-9 paper-title">
    <b>Evaluating Semantic Accuracy of Data-to-Text Generation with Natural Language Inference
    </b> 
    </div>
    <div class="col-md-3 paper-buttons">
    <a href="https://www.aclweb.org/anthology/2020.inlg-1.19/" target="_blank" class="btn btn-acl" role="button"><i class="fa fa-file-pdf"></i></a>
    <a href="https://github.com/ufal/nlgi_eval" target="_blank" class="btn btn-code" role="button"><i class="fa fa-github"></i></a>
    </div>
    </div>
    <div class="paper-authors">
    <i>Ondřej Dušek, Zdeněk Kasner; INLG 2020</i>
    </div>
    
    <div class="paper-desc" style="margin-top: 10px">
        Does a text contain all the information from the data? Hard to check manually, even harder to code. But what if we reformulate the question a little bit: can we <i>infer</i> all the data from the text and nothing else? That sounds like natural language inference. And guess what - somebody already pretrained a neural model for that!
    </div>
    <div class="paper-img">
        <img src="/assets/papers/2020_nli_inlg.png">
    </div>
</div>

<hr>

<div class="paper">
    <div class="row">
    <div class="col-md-8 paper-title">
    <b>Data-to-Text Generation with Iterative Text Editing</b> 
    </div>
    <div class="col-md-4  paper-buttons">
        <a href="https://www.aclweb.org/anthology/2020.inlg-1.9/" target="_blank" class="btn btn-acl" role="button"><i class="fa fa-file-pdf"></i></a>
        <a href="/assets/papers/pdf/2020_d2t_text_editing.pdf" target="_blank" class="btn btn-poster" role="button"><i class="fa fa-file-invoice"></i></a>
        <a href="https://github.com/kasnerz/d2t_iterative_editing" target="_blank" class="btn btn-code" role="button"><i class="fa fa-github"></i></a>
    </div>
    </div>
    <div class="paper-authors">
    <i>Zdeněk Kasner, Ondřej Dušek; INLG 2020</i>
    </div>
    <div style="margin-top: 10px">
        <p>
        Imagine your task is to generate text from data. Which sounds easier: <i>generating text from scratch</i> or <i>joining existing sentences</i>?
        </p><p>
        In our approach for the data-to-text generation, we convert data to simple sentences using templates and iteratively join the sentences with a neural model. The model doesn't generate the sentences from scratch, so it cannot mess with the sentences too much. And it also turns out that we can apply the same model for related domains!
        </p>
    </div>
    <div class="paper-img">
    <img src="/assets/papers/2020_d2t_text_editing.png">
    </div>
</div>

<hr>

<div class="paper">
    <div class="row">
    <div class="col-md-9 paper-title">
    <b>Improving Fluency of Non-Autoregressive Machine Translation</b> 
    </div>
    <div class="col-md-3  paper-buttons">
    <a href="https://arxiv.org/abs/2004.03227" target="_blank" class="btn btn-arxiv" role="button"><i class="fa fa-file-pdf"></i></a>
    <a href="https://github.com/kasnerz/neuralmonkey-ctc-decoder" target="_blank" class="btn btn-code" role="button"><i class="fa fa-github"></i></a>
    </div>
    </div>
    <div class="paper-authors">
    <i>Zdeněk Kasner, Jindřich Libovický, Jindřich Helcl</i>
    </div>
    <div style="margin-top: 10px">
    A follow-up of my master thesis in which we improve translation quality of a CTC-based machine translation model. The model is non-autoregressive, i.e. faster but not as good as autoregressive models. To achieve that, we re-score the hypotheses in the beam of the model with a language model and several other features.
    </div>
    <div class="paper-img">
        <img src="/assets/papers/2019_nonautoregressive.png" width="300" style="margin-top:20px;margin-left:auto; margin-right:auto; display:block">
    </div>
</div>

<hr>